<!DOCTYPE html>
<!-- saved from url=(0059)https://boxbase.org/entries/2019/oct/14/lr1-parsing-tables/ -->
<html lang="en" data-darkreader-mode="dynamic" data-darkreader-scheme="dark"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><style class="darkreader darkreader--fallback" media="screen"></style><style class="darkreader darkreader--text" media="screen"></style><style class="darkreader darkreader--invert" media="screen">.jfk-bubble.gtx-bubble, .captcheck_answer_label > input + img, span#closed_text > img[src^="https://www.gstatic.com/images/branding/googlelogo"], span[data-href^="https://www.hcaptcha.com/"] > #icon, #bit-notification-bar-iframe, ::-webkit-calendar-picker-indicator {
    filter: invert(100%) hue-rotate(180deg) contrast(90%) !important;
}</style><style class="darkreader darkreader--inline" media="screen">[data-darkreader-inline-bgcolor] {
  background-color: var(--darkreader-inline-bgcolor) !important;
}
[data-darkreader-inline-bgimage] {
  background-image: var(--darkreader-inline-bgimage) !important;
}
[data-darkreader-inline-border] {
  border-color: var(--darkreader-inline-border) !important;
}
[data-darkreader-inline-border-bottom] {
  border-bottom-color: var(--darkreader-inline-border-bottom) !important;
}
[data-darkreader-inline-border-left] {
  border-left-color: var(--darkreader-inline-border-left) !important;
}
[data-darkreader-inline-border-right] {
  border-right-color: var(--darkreader-inline-border-right) !important;
}
[data-darkreader-inline-border-top] {
  border-top-color: var(--darkreader-inline-border-top) !important;
}
[data-darkreader-inline-boxshadow] {
  box-shadow: var(--darkreader-inline-boxshadow) !important;
}
[data-darkreader-inline-color] {
  color: var(--darkreader-inline-color) !important;
}
[data-darkreader-inline-fill] {
  fill: var(--darkreader-inline-fill) !important;
}
[data-darkreader-inline-stroke] {
  stroke: var(--darkreader-inline-stroke) !important;
}
[data-darkreader-inline-outline] {
  outline-color: var(--darkreader-inline-outline) !important;
}
[data-darkreader-inline-stopcolor] {
  stop-color: var(--darkreader-inline-stopcolor) !important;
}</style><style class="darkreader darkreader--variables" media="screen">:root {
   --darkreader-neutral-background: #131516;
   --darkreader-neutral-text: #d8d4cf;
   --darkreader-selection-background: #004daa;
   --darkreader-selection-text: #e8e6e3;
}</style><style class="darkreader darkreader--root-vars" media="screen"></style><style class="darkreader darkreader--user-agent" media="screen">html {
    background-color: #181a1b !important;
}
html {
    color-scheme: dark !important;
}
html, body {
    background-color: #181a1b;
}
html, body {
    border-color: #736b5e;
    color: #e8e6e3;
}
a {
    color: #3391ff;
}
table {
    border-color: #545b5e;
}
::placeholder {
    color: #b2aba1;
}
input:-webkit-autofill,
textarea:-webkit-autofill,
select:-webkit-autofill {
    background-color: #404400 !important;
    color: #e8e6e3 !important;
}
::-webkit-scrollbar {
    background-color: #202324;
    color: #aba499;
}
::-webkit-scrollbar-thumb {
    background-color: #454a4d;
}
::-webkit-scrollbar-thumb:hover {
    background-color: #575e62;
}
::-webkit-scrollbar-thumb:active {
    background-color: #484e51;
}
::-webkit-scrollbar-corner {
    background-color: #181a1b;
}
::selection {
    background-color: #004daa !important;
    color: #e8e6e3 !important;
}
::-moz-selection {
    background-color: #004daa !important;
    color: #e8e6e3 !important;
}</style>
<link href="./How to write your own LR(1) parsing tables (and generate them)_files/css" rel="stylesheet" type="text/css">

<meta content="width=device-width, initial-scale=1" name="viewport">
<meta content="Henri Tuhola" name="author">
<meta content="Here I show you how to write your own LR(1) parser without any tools whatsoever. I also invite people to write their own parsers whole this month." name="description">
<title>How to write your own LR(1) parsing tables (and generate them)</title>
<meta content="website" property="og:type">
<meta content="How to write your own LR(1) parsing tables (and generate them)" property="og:title">
<meta content="Here I show you how to write your own LR(1) parser without any tools whatsoever. I also invite people to write their own parsers whole this month." property="og:description">
<meta content="https://boxbase.org/style/boxbase.svg" property="og:image">
<meta content="https://boxbase.org//entries/2019/oct/14/lr1-parsing-tables" property="og:url">
<link href="./How to write your own LR(1) parsing tables (and generate them)_files/screen.css" rel="stylesheet"><style class="darkreader darkreader--sync" media="screen"></style>
<link href="https://boxbase.org/feed.rss" rel="alternate" title="Boxbase Feed" type="application/rss+xml">
<meta name="darkreader" content="5adfd6b88cc54faa9fa7f26a9a030359"><style class="darkreader darkreader--override" media="screen">.vimvixen-hint {
    background-color: #7b5300 !important;
    border-color: #d8b013 !important;
    color: #f3e8c8 !important;
}
::placeholder {
    opacity: 0.5 !important;
}
#edge-translate-panel-body,
.MuiTypography-body1,
.nfe-quote-text {
    color: var(--darkreader-neutral-text) !important;
}
gr-main-header {
    background-color: #0f3a48 !important;
}
.tou-z65h9k,
.tou-mignzq,
.tou-1b6i2ox,
.tou-lnqlqk {
    background-color: var(--darkreader-neutral-background) !important;
}
.tou-75mvi {
    background-color: #032029 !important;
}
.tou-ta9e87,
.tou-1w3fhi0,
.tou-1b8t2us,
.tou-py7lfi,
.tou-1lpmd9d,
.tou-1frrtv8,
.tou-17ezmgn {
    background-color: #0a0a0a !important;
}
.tou-uknfeu {
    background-color: #231603 !important;
}
.tou-6i3zyv {
    background-color: #19576c !important;
}
embed[type="application/pdf"][src="about:blank"] { filter: invert(100%) contrast(90%); }</style></head>
<body>
<article><h1>How to write your own LR(1) parsing tables (and generate them)</h1>
<p>There are few reasons why you might like to consider
rolling your own parsing tables.</p>
<ol>
<li>LR parsers are structurally quite simple and easy to understand.</li>
<li>It may help you figure out what's going wrong
if you ever use a parser generator.</li>
<li>It can be a quite easy way to get a parser
if you otherwise don't want to use any parsing tools
in your programming environment.</li>
</ol>
<p>Warning: I found some bugs in the code,
  There's corrected code in the <a href="https://boxbase.org/entries/2019/oct/14/21/layout-sensitive-lr/">next post</a>.</p>
<h2>Prerequisites</h2>
<p>To follow through here, you are going to need...</p>
<ol>
<li>A text editor</li>
<li>A grammar, I am going to use an interesting fragment of
<a href="https://github.com/Ratstail91/Toy/blob/master/docs/grammar">Ratstail91's Toy language</a>
because he supplied a context-free grammar for it.</li>
</ol>
<p>That's all you need.
Though if you want to implement a parser with your parsing tables,
you also need a programming language
and tools to run programs in your language.
We will get to that later.</p>
<h2>What is a context-free grammar?</h2>
<p>We work with context-free grammars and
I assume you already know what they are,
but if you don't here's a short explanation.</p>
<p>A context-free grammar is a bunch of rules to form sentences.
The way they work is that group of symbols may stand for other symbols.
For example, if in the grammar we have:</p>
<pre><code>breakStmt → "break" ";"</code></pre>
<p>This means that if we need to produce a 'breakStmt',
we can form it from "break" and ";" -symbols.</p>
<p>Author of the grammar has helpfully separated the lexemes
of the language by wrapping them into parentheses.
These are small units that make the actual sentence.
It's not always necessary to separate the lexemes from symbols,
but LR(1) parser benefits from knowing which symbols are lexemes.</p>
<p>Additionally the grammar uses some small symbols
to succinctly express the production rules and the language.
We have stars, question marks, parentheses wrapped around symbols,
vertical columns.
These have fairly standard meanings and I open them up as we go.</p>
<h2>What is a LR parser?</h2>
<p>LR parser is a program that recognizes and parses
such sentences as presented above.
I'd assume you know this too.</p>
<p>LR parser is constructed from a <a href="https://en.wikipedia.org/wiki/Pushdown_automaton">pushdown-automaton</a>
Pushdown-automaton is a <a href="https://en.wikipedia.org/wiki/Finite-state_machine">finite-state machine</a> that employs a stack.</p>
<p>LR parser does either shift or reduce depending on state and input.</p>
<ol>
<li>Shift takes a symbol from the input stream
adds the symbol and current state into the stack
then advances to another state.</li>
<li>Reduce takes 'n' items from the stack,
restores the state recorded into the stack,
then puts a new symbol to the front of the input stream.</li>
</ol>
<p>It may sound very remote from what you think would be involved in
recognizing sentences of some language,
but that's sufficient for some grammars.</p>
<p>If you can take your grammar and construct a decision table for the LR parser,
then you have a grammar that can be parsed with a LR parser.
If you don't have such grammar
then you have shift/reduce and reduce/reduce conflicts.
I will explain those in a moment.</p>
<h2>Dotted rules, or "items"</h2>
<p>There's a way to split the parsing of context-free grammars into smaller steps.
This happens by tracking where we "are" in the grammar
during parsing.
We can accomplish this by moving dots inside production rules of the grammar.
When you start parsing some rule you give it a dot
before the first symbol that we expect to see,
like this:</p>
<pre><code>breakStmt → ∘ "break" ";"</code></pre>
<p>If we've already seen the "break" -symbol in the input,
the dot has moved to the right side of it:</p>
<pre><code>breakStmt → "break" ∘ ";"</code></pre>
<p>And if Thomas has seen everything from the crime scene,
planning for a swift escape through the rail system,
we have:</p>
<pre><code>breakStmt → "break" ";" ∘</code></pre>
<p>This kind of an item is usually called "reduction" item whereas
the kind where the dot is on the first location is called "prediction" item.
Of course you may also start parsing from the right side in which case
these terms are flipped around and you get different parsing tables.</p>
<h2>The main event</h2>
<p>I've explained what we are working with,
so it's time to get on the main event of this post.
Lets create those decision tables.</p>
<p>We start with a prediction item for what we're expecting to parse:</p>
<pre><code>⊤ → ∘ program</code></pre>
<p>Then you look at the thing on the right side of the dot.
If there's a rule to produce it,
you predict that rule is needed and add it under the item:</p>
<pre><code>0: ⊤ → ∘ program
</code><code>   program → ∘
</code><code>   program → ∘ program declaration</code></pre>
<p>The program-rule had a star in it,
this commonly means the item coming after the star repeats zero or more times.
I rewrote the star away from the grammar and got the above two rules.
Note that although the second item is empty,
we don't need to do anything special here.
The first set of items is complete and now we shift with each symbol that
appears on the right side of a dot, ending up with this:</p>
<pre><code>1: ⊤ → program ∘
</code><code>   program → program ∘ declaration</code></pre>
<p>Each item set is numbered, the first set was 0, this is 1.
Now we have to predict that we parse declarations here:</p>
<pre><code>1: ⊤ → program ∘
</code><code>   program → program ∘ declaration 
</code><code>   declaration → ∘ varDecl
</code><code>   declaration → ∘ constDecl
</code><code>   declaration → ∘ statement</code></pre>
<p>Hopefully you now understand what the vertical columns mean in the grammar.
It's a convenience to describe multiple production rules at once.</p>
<p>We would repeat prediction for every symbol we have.
For now I leave this here,
lets assume 'varDecl', 'constDecl' and 'statement' are our lexemes.</p>
<p>There are bunch of symbols we can shift with.
Shifting each would produce the following further item sets:</p>
<pre><code>2: program → program declaration ∘
</code><code>
</code><code>3: declaration → varDecl ∘
</code><code>
</code><code>4: declaration → constDecl ∘
</code><code>
</code><code>5: declaration → statement ∘</code></pre>
<p>If we get identical initial item sets, we may collapse them together.
This means we eventually end up having multiple shifts.
By the way record those shifts:</p>
<pre><code>0: program:     Shift 1
</code><code>1: declaration: Shift 2
</code><code>   varDecl:     Shift 3
</code><code>   constDecl:   Shift 4
</code><code>   statement:   Shift 5
</code><code>2:
</code><code>3:
</code><code>4:
</code><code>5:</code></pre>
<p>That is actually the shifting part of the decision table.
Next we need to consider what the reduction part is.
We can retrieve the following reduction items from the grammar:</p>
<pre><code>0: program → ∘
</code><code>1: ⊤ → program ∘
</code><code>2: program → program declaration ∘
</code><code>3: declaration → varDecl ∘
</code><code>4: declaration → constDecl ∘
</code><code>5: declaration → statement ∘</code></pre>
<p>There may be multiple reduction items in an item set.</p>
<p>If we can't determine which rule to reduce with,
we get a reduce/reduce conflict.
Likewise if we can't determine whether to reduce or shift,
we get a shift/reduce conflict.</p>
<p>Now if we left this to here, we'd have a shift/reduce conflict in the
item sets 0 and 1.
Otherwise the table would look like this:</p>
<pre><code>0: program:     Shift 1 / Reduce 0 program
</code><code>1: declaration: Shift 2 / Reduce 1 ⊤ 
</code><code>   varDecl:     Shift 3 / Reduce 1 ⊤ 
</code><code>   constDecl:   Shift 4 / Reduce 1 ⊤ 
</code><code>   statement:   Shift 5 / Reduce 1 ⊤ 
</code><code>2: Reduce 2 program
</code><code>3: Reduce 1 declaration
</code><code>4: Reduce 1 declaration
</code><code>5: Reduce 1 declaration</code></pre>
<p>The 'Reduce' -record contains
how many items to remove and the shifting symbol.
Practically you might add a number to the reduction rule that is applied,
but this is sufficient.</p>
<p>Next we can try to get rid of the shift/reduction issues.
This happens through constructing FIRST/FOLLOW -sets for conflicts.
Basically the point is to find out whether we can carve a
hole for the shifting table.</p>
<h2>FIRST(symbol) -set</h2>
<p>The first task is to determine which symbols may start with which lexemes.
We would conclude the following:</p>
<pre><code>FIRST(⊤) = {}
</code><code>FIRST(program) = {}
</code><code>FIRST(declaration) = {varDecl,constDecl,statement}
</code><code>FIRST(varDecl) = {varDecl}
</code><code>FIRST(constDecl) = {constDecl}
</code><code>FIRST(statement) = {statement}</code></pre>
<p>If you don't know which symbols are lexemes appearing in the input stream,
you got to assume all of them are.</p>
<h2>FOLLOW(itemset, symbol) -set</h2>
<p>Second we have to trace which lexemes
can appear after the symbol has been shifted.
In the very first state,
we have declaration and nothing appearing after a program symbol.</p>
<pre><code>0: ⊤ → ∘ program
</code><code>   program → ∘
</code><code>   program → ∘ program declaration</code></pre>
<p>And therefore:</p>
<pre><code>FOLLOW(0, program) = {Ø1,varDecl,constDecl,statement}</code></pre>
<p>Note we have marked out there can be nothing following a program,
and which rule in the set it was, those are details we need to know as well.</p>
<p>Here are the remaining pieces of the 'FOLLOW' -set.</p>
<pre><code>FOLLOW(1, declaration) = {Ø1}
</code><code>FOLLOW(1, varDecl) = {Ø2}
</code><code>FOLLOW(1, constDecl) = {Ø3}
</code><code>FOLLOW(1, statement) = {Ø4}</code></pre>
<p>And that's all what we have for the small fragment of grammar we picked.</p>
<h2>Resolving the decision table</h2>
<p>Now we have the information we need to resolve conflicts in the earlier table.
We start by declaring that after the first state
we expect to see the input stream end:</p>
<pre><code>0: ⊤ → ∘ program {$}
</code><code>   program → ∘ {$,varDecl,constDecl,statement}
</code><code>   program → ∘ program declaration {$,varDecl,constDecl,statement}</code></pre>
<p>The sets in end of each item are lookahead sets and describe
what is expected after the rule.
There are bit of shenanigans going on here because we have to predict
the program rule follows itself.</p>
<p>Now we can conclude the first state is:</p>
<pre><code>0: $:           Reduce 0 program
</code><code>   varDecl:     Reduce 0 program
</code><code>   constDecl:   Reduce 0 program
</code><code>   statement:   Reduce 0 program
</code><code>   program:     Shift 1</code></pre>
<p>We do the shift like before:</p>
<pre><code>1: ⊤ → program ∘ {$}
</code><code>   program → program ∘ declaration {$,varDecl,constDecl,statement}
</code><code>   declaration → ∘ varDecl {$,varDecl,constDecl,statement}
</code><code>   declaration → ∘ constDecl {$,varDecl,constDecl,statement}
</code><code>   declaration → ∘ statement {$,varDecl,constDecl,statement}</code></pre>
<p>Note the predictions are done the same way as before,
except that they get their own lookahead sets.
Now we know that reductions do not collide with shifting anywhere:</p>
<pre><code>1: $:           Reduce 1 ⊤ 
</code><code>   declaration: Shift 2
</code><code>   varDecl:     Shift 3
</code><code>   constDecl:   Shift 4
</code><code>   statement:   Shift 5</code></pre>
<p>And we can do the same as before:</p>
<pre><code>2: program → program declaration ∘ {$,varDecl,constDecl,statement}
</code><code>3: declaration → varDecl ∘ {$,varDecl,constDecl,statement}
</code><code>4: declaration → constDecl ∘ {$,varDecl,constDecl,statement}
</code><code>5: declaration → statement ∘ {$,varDecl,constDecl,statement}</code></pre>
<p>This allows to conclude that 'Reduce 0 program'
is only needed at the end of the input stream.</p>
<p>Since we shift to the state 1 with program,
we'd like to know what we are expecting after the 'program'.
This is revealed by the <code>FOLLOW(0,program)</code> and it tells we got
empty state and the declaration items.
The empty state is substituted by the lookahead set in the current state.</p>
<pre><code>0: $:           Reduce 0 program
</code><code>   varDecl:     Reduce 0 program
</code><code>   constDecl:   Reduce 0 program
</code><code>   statement:   Reduce 0 program
</code><code>   program:     Shift 1
</code><code>1: $:           Reduce 1 ⊤ 
</code><code>   declaration: Shift 2
</code><code>   varDecl:     Shift 3
</code><code>   constDecl:   Shift 4
</code><code>   statement:   Shift 5
</code><code>2: $:           Reduce 2 program
</code><code>   varDecl:     Reduce 2 program
</code><code>   constDecl:   Reduce 2 program
</code><code>   statement:   Reduce 2 program
</code><code>3: $:           Reduce 1 declaration
</code><code>   varDecl:     Reduce 1 declaration
</code><code>   constDecl:   Reduce 1 declaration
</code><code>   statement:   Reduce 1 declaration
</code><code>4: $:           Reduce 1 declaration
</code><code>   varDecl:     Reduce 1 declaration
</code><code>   constDecl:   Reduce 1 declaration
</code><code>   statement:   Reduce 1 declaration
</code><code>5: $:           Reduce 1 declaration
</code><code>   varDecl:     Reduce 1 declaration
</code><code>   constDecl:   Reduce 1 declaration
</code><code>   statement:   Reduce 1 declaration</code></pre>
<p>Now you have your parser's decision table there.
This concludes the main content in this guide.</p>
<h2>Okay, how to build a parser around that?</h2>
<p>To make a parser, we need bit of machinery,
then we have to encode the table in the language that we use:</p>
<pre><code>class State:
</code><code>    def __init__(self):
</code><code>        self.stack = []
</code><code>        self.top = 0
</code><code>
</code><code>def advance(st, next_symbol):
</code><code>    while state[st.top][next_symbol](st):
</code><code>        pass
</code><code>
</code><code>def shift(to):
</code><code>    def _shift_(st):
</code><code>        print('shift {}'.format(to))
</code><code>        st.stack.append(st.top)
</code><code>        st.top = to
</code><code>        return False
</code><code>    return _shift_
</code><code>
</code><code>def red(count, symbol):
</code><code>    def _red_(st):
</code><code>        for _ in range(count):
</code><code>            st.top = st.stack.pop()
</code><code>        print('reduce {}'.format(symbol))
</code><code>        state[st.top][symbol](st)
</code><code>        return True
</code><code>    return _red_
</code><code>
</code><code>def accept():
</code><code>    def _accept_(st):
</code><code>        st.top = st.stack.pop()
</code><code>        print 'accepted'
</code><code>        return False
</code><code>    return _accept_
</code><code>
</code><code>state = [
</code><code>    {'$':           red(0, 'program'),
</code><code>     'varDecl':     red(0, 'program'),
</code><code>     'constDecl':   red(0, 'program'),
</code><code>     'statement':   red(0, 'program'),
</code><code>     'program':     shift(1)},
</code><code>    {'$':           accept(),
</code><code>     'declaration': shift(2),
</code><code>     'varDecl':     shift(3),
</code><code>     'constDecl':   shift(4),
</code><code>     'statement':   shift(5)},
</code><code>    {'$':           red(2, 'program'),
</code><code>     'varDecl':     red(2, 'program'),
</code><code>     'constDecl':   red(2, 'program'),
</code><code>     'statement':   red(2, 'program')},
</code><code>    {'$':           red(1, 'declaration'),
</code><code>     'varDecl':     red(1, 'declaration'),
</code><code>     'constDecl':   red(1, 'declaration'),
</code><code>     'statement':   red(1, 'declaration')},
</code><code>    {'$':           red(1, 'declaration'),
</code><code>     'varDecl':     red(1, 'declaration'),
</code><code>     'constDecl':   red(1, 'declaration'),
</code><code>     'statement':   red(1, 'declaration')},
</code><code>    {'$':           red(1, 'declaration'),
</code><code>     'varDecl':     red(1, 'declaration'),
</code><code>     'constDecl':   red(1, 'declaration'),
</code><code>     'statement':   red(1, 'declaration')}]</code></pre>
<p>Now you have a recognizer, you can recognize sentences in your language like this:</p>
<pre><code># Successful parse
</code><code>st = State()
</code><code>advance(st, 'statement')
</code><code>advance(st, 'varDecl')
</code><code>advance(st, '$')
</code><code>print(st.stack)
</code><code>print(st.top)
</code><code>
</code><code># Failing parse
</code><code>st = State()
</code><code>advance(st, 'statement')
</code><code>advance(st, 'foo')</code></pre>
<p>Route the output of your lexical analyzer into the 'advance'
and you are recognizing strings.
To turn it into a parser you add a routine to build values within
the 'shift' and 'reduce' -steps.</p>
<p>How would it look like then?
It would look like this:</p>
<pre><code>class State:
</code><code>    def __init__(self):
</code><code>        self.stack = []
</code><code>        self.forest = []
</code><code>        self.top = 0
</code><code>
</code><code>def advance(st, next_symbol, value):
</code><code>    while state[st.top][next_symbol](st, value):
</code><code>        pass
</code><code>
</code><code>def shift(to):
</code><code>    def _shift_(st, value):
</code><code>        st.stack.append(st.top)
</code><code>        st.forest.append(value)
</code><code>        st.top = to
</code><code>        return False
</code><code>    return _shift_
</code><code>
</code><code>def red(count, symbol, name):
</code><code>    def _red_(st, value):
</code><code>        args = []
</code><code>        for _ in range(count):
</code><code>            st.top = st.stack.pop()
</code><code>            args.append(st.forest.pop())
</code><code>        args.append(":" + name)
</code><code>        args.reverse()
</code><code>        state[st.top][symbol](st, args)
</code><code>        return True
</code><code>    return _red_
</code><code>
</code><code>def accept():
</code><code>    def _accept_(st, value):
</code><code>        st.top = st.stack.pop()
</code><code>        item = st.forest.pop()
</code><code>        print('accepted {}'.format(item))
</code><code>        return False
</code><code>    return _accept_
</code><code>
</code><code>state = [
</code><code>    {'$':           red(0, 'program', 'empty'),
</code><code>     'varDecl':     red(0, 'program', 'empty'),
</code><code>     'constDecl':   red(0, 'program', 'empty'),
</code><code>     'statement':   red(0, 'program', 'empty'),
</code><code>     'program':     shift(1)},
</code><code>    {'$':           accept(),
</code><code>     'declaration': shift(2),
</code><code>     'varDecl':     shift(3),
</code><code>     'constDecl':   shift(4),
</code><code>     'statement':   shift(5)},
</code><code>    {'$':           red(2, 'program', 'sequence'),
</code><code>     'varDecl':     red(2, 'program', 'sequence'),
</code><code>     'constDecl':   red(2, 'program', 'sequence'),
</code><code>     'statement':   red(2, 'program', 'sequence')},
</code><code>    {'$':           red(1, 'declaration', 'var'),
</code><code>     'varDecl':     red(1, 'declaration', 'var'),
</code><code>     'constDecl':   red(1, 'declaration', 'var'),
</code><code>     'statement':   red(1, 'declaration', 'var')},
</code><code>    {'$':           red(1, 'declaration', 'const'),
</code><code>     'varDecl':     red(1, 'declaration', 'const'),
</code><code>     'constDecl':   red(1, 'declaration', 'const'),
</code><code>     'statement':   red(1, 'declaration', 'const')},
</code><code>    {'$':           red(1, 'declaration', 'statement'),
</code><code>     'varDecl':     red(1, 'declaration', 'statement'),
</code><code>     'constDecl':   red(1, 'declaration', 'statement'),
</code><code>     'statement':   red(1, 'declaration', 'statement')}]
</code><code>
</code><code># Successful parse
</code><code>st = State()
</code><code>advance(st, 'statement', '123 = 4')
</code><code>advance(st, 'varDecl', 'var abc')
</code><code>advance(st, '$', None)
</code><code>print(st.stack)
</code><code>print(st.top)
</code><code>
</code><code># Failing parse
</code><code>st = State()
</code><code>advance(st, 'statement', '123 = 4')
</code><code>advance(st, 'foo', 'foo')</code></pre>
<p>Likewise adding line/column numbering isn't hard.</p>
<h2>Layout sensitivity?</h2>
<p>So after you read this, and you've been fan of a Python,
you are going to ask how to get layout sensitivity,
off-side rule, indentation syntax, it's got many names.</p>
<p>If you can formally model your language,
you don't depend on any purpose-built tools.
So I describe you a working way to model a layout-sensitive language
with context-free grammars first.</p>
<p>So bit of theory first.. When layout has a syntactic meaning,
how would you describe what layout is?
In simplest sense of the word, I think it means that the "box" or shape
of the sentence is interpreted as a structure.
For example, if you have addition spread across two lines:</p>
<pre><code>1234
</code><code> + 2345</code></pre>
<p>You could imagine this forms a box that encloses this expression.
Likewise every lexeme forms its own box that encloses the lexeme.</p>
<p>You are going to need a special lexeme labeled 'VALIGN'.
This lexeme is recognized if the adjacent symbols align vertically.</p>
<p>Next we are going to need a modifier 'WFB'.
This denotes that a symbol coming after it must form a well-formed-boundary.
The idea with a well-formed-boundary is that the leftmost symbol is
the only symbol that hits the left boundary of the box that encloses the expression.</p>
<p>Now we can describe a statement block like this:</p>
<pre><code>block → WFB statement
</code><code>block → block VALIGN WFB statement</code></pre>
<p>You could have different kind of constraints defined in a same way.
It'd be sensible to require syntactic elements to right-align, or to
align in square, or about anything you can think of.
Though these two constraints will provide a convenient implementation
in the LR parser.</p>
<p>The WFB can be implemented by inserting a layout constraint while shifting.
Implement it right and the reduction step erases the constraint
when it no longer applies.
Likewise you cloak the lookahead set below behind the WFB so there are no
conflicts that would be there without the layout.</p>
<p>The 'VALIGN' can be interpreted as a prefix for the symbol following it.
You ignore it in the lookahead-sets and mark a constraint on the shift:
"the item shifted in must align vertically with previously shifted item".</p>
<p>The layout sensitivity introduces two possible new conflicts:
WFB and VALIGN -conflicts.
These happen when the shifts do not align or constraint like they should.</p>
<p>That's all, you can make your language layout sensitive this way.
If you don't believe I show you here, with a language that has a block
with some statements:</p>
<pre><code>0: block → ∘ WFB statement {$}
</code><code>   block → ∘ block VALIGN WFB statement {$}
</code><code>   statement → ∘ identifier eq expr [wfb] {wfb,$}
</code><code>   statement → ∘ expr [wfb] {wfb,$}
</code><code>1: block → WFB statement ∘ {$}
</code><code>2: block → block ∘ VALIGN WFB statement {$}
</code><code>   statement → ∘ identifier eq expr [valign,wfb] {wfb,$}
</code><code>   statement → ∘ expr [valign,wfb] {wfb,$}
</code><code>3: block → block VALIGN WFB statement ∘ {$}
</code><code>4: statement → identifier ∘ eq expr {wfb,$}
</code><code>5: statement → identifier eq ∘ expr {wfb,$}
</code><code>6: statement → identifier eq expr ∘ {wfb,$}
</code><code>7: statement → expr ∘ {wfb,$}</code></pre>
<p>Note that wfb -conceals 'statement' because of the VALIGN.
Otherwise it would not.</p>
<p>Ok, next the decision table:</p>
<pre><code>0: statement:  Shift 1
</code><code>   block:      Shift 2
</code><code>   identifier: WFB Shift 4
</code><code>   expr:       WFB Shift 7
</code><code>1: $:          Reduce 1 block
</code><code>2: statement:  Shift 3
</code><code>   identifier: VALIGN WFB Shift 4
</code><code>   expr:       VALIGN WFB Shift 7
</code><code>3: $:          Reduce 2 block
</code><code>4: eq:         Shift 5
</code><code>5: expr:       Shift 6
</code><code>6: wfb:        Reduce 3 statement
</code><code>   $:          Reduce 3 statement
</code><code>7: wfb:        Reduce 1 statement
</code><code>   $:          Reduce 1 statement</code></pre>
<p>There you have it.
With this you can build indented languages
where the block statement can be inlined.
For example:</p>
<pre><code>sub loader:
</code><code>  element.addListener('click',
</code><code>    sub x, y: console.log(x)
</code><code>              console.log(y))</code></pre>
<p>Also you can parse those transition tables, or grammars without end markers.</p>
<h2>A tokenizer</h2>
<p>I know somebody gets excited about building a programming language.
Therefore I give you a short snippet that shows how to write a tokenizer.
This is a finite state machine,
and when you plug 'advance' to the place of the 'on_output'
and shape it a bit, you can attach this tokenizer to the parser.</p>
<p>Just like before, you can stick to finite state machines
to be formal enough that you have a properly defined language.</p>
<pre><code>class Tokenizer:
</code><code>    def __init__(self, on_output):
</code><code>        self.on_output = on_output
</code><code>        self.state = 'st_0'
</code><code>        self.column = 1
</code><code>        self.line   = 1
</code><code>        self.pos = (1,1)
</code><code>        self.inp = []
</code><code>
</code><code>def st_0(tok, ch):
</code><code>    if ch.isdigit():
</code><code>        tok.pos = (tok.column, tok.line)
</code><code>        tok.inp.append(ch)
</code><code>        tok.state = 'st_digits'
</code><code>    elif ch.isalpha() or ch == "_":
</code><code>        tok.pos = (tok.column, tok.line)
</code><code>        tok.inp.append(ch)
</code><code>        tok.state = 'st_word'
</code><code>    elif ch == " " or ch == "\n" or ch == "\t" or ch == "\r":
</code><code>        pass
</code><code>    else:
</code><code>        tok.on_output('error', ch,
</code><code>            (tok.column, tok.line), (tok.column+1, tok.line))
</code><code>
</code><code>def st_word(tok, ch):
</code><code>    if ch.isalpha() or ch == "_" or ch.isdigit():
</code><code>        tok.inp.append(ch)
</code><code>    else:
</code><code>        tok.on_output('word', "".join(tok.inp),
</code><code>            tok.pos, (tok.column+1, tok.line))
</code><code>        tok.inp = []
</code><code>        tok.state = 'st_0'
</code><code>        st_0(tok, ch)
</code><code>
</code><code>def st_digits(tok, ch):
</code><code>    if ch.isdigit():
</code><code>        tok.inp.append(ch)
</code><code>    else:
</code><code>        tok.on_output('digits', "".join(tok.inp),
</code><code>            tok.pos, (tok.column+1, tok.line))
</code><code>        tok.inp = []
</code><code>        tok.state = 'st_0'
</code><code>        st_0(tok, ch)
</code><code>
</code><code># Collects every 'st_' into a dictionary.
</code><code>tokenize_n = dict((k,v) for k,v in globals().items()
</code><code>    if k.startswith('st_'))
</code><code>
</code><code>def tokenize(tok, ch):
</code><code>    tokenize_n[tok.state](tok, ch)
</code><code>    if ch == "\n":
</code><code>        tok.line += 1
</code><code>        tok.column = 1
</code><code>    else:
</code><code>        tok.column += 1</code></pre>
<p>Here's how you use this:</p>
<pre><code>def print_on_output(item, text, start, stop):
</code><code>    print((item, repr(text), start, stop))
</code><code>
</code><code>tok = Tokenizer(print_on_output)
</code><code>with open("input-file", "r") as fd:
</code><code>    for ch in fd.read():
</code><code>        tokenize(tok, ch)</code></pre>
<p>Note that if you allow the parser to trigger multiple times
and connect 'accept' to a responder of some kind,
it lets you build communication protocols with this thing.</p>
<h2>A little advice on error recovery</h2>
<p>There's overall good advice on writing good language interfaces
that I'd like to tell you about.
The advice is: Don't let the parser stop on errors.</p>
<p>You see it's a good idea to report an error and not let the program proceed
through a point where the error happened.
But it's a generally bad idea to have the program stop there
and stop all the work.</p>
<p>By the time you get that first error there's a subsequent question
of what else did go wrong.</p>
<p>The layout parser presented earlier does especially help here.
It precisely marks out points where you can drop out
and expect the program follows the same shape once it's been fixed.</p>
<h2>Computer 'assisted' LR decision table generation</h2>
<p>Now lets generate an another decision table,
except that this time we let the computer do the bulk work.</p>
<p>Lets use the same grammar as before:</p>
<pre><code>⊤ → program
</code><code>program → 
</code><code>program → program declaration 
</code><code>declaration → varDecl
</code><code>declaration → constDecl
</code><code>declaration → statement
</code><code>
</code><code>lexemes: varDecl,constDecl,statement</code></pre>
<p>We can represent the whole grammar like this:</p>
<pre><code>grammar = [
</code><code>    (None, ['program']),
</code><code>    ('program', []),
</code><code>    ('program', ['program', 'declaration']),
</code><code>    ('declaration', ['varDecl']),
</code><code>    ('declaration', ['constDecl']),
</code><code>    ('declaration', ['statement']),
</code><code>]
</code><code>lexemes = ['varDecl', 'constDecl', 'statement']</code></pre>
<p>The dotted rules are pairs of indices because those are easy to work with.</p>
<pre><code>def print_grammar():
</code><code>    for lhs, rhs in grammar:
</code><code>        print("{} → {}".format(lhs or '⊤', " ".join(rhs)))
</code><code>
</code><code>def print_item(prefix, (rule, index)):
</code><code>    lhs, rhs = grammar[rule]
</code><code>    print("{}{} → {}".format(prefix, lhs or '⊤',
</code><code>        " ".join(rhs[:index] + ['∘'] + rhs[index:])))
</code><code>
</code><code>def print_itemset(index, items):
</code><code>    prefix = "{}: ".format(index)
</code><code>    for item in items:
</code><code>        print_item(prefix, item)
</code><code>        prefix = " " * len(prefix)</code></pre>
<p>Now if we wanted to print the first itemset, it'd look like this:</p>
<pre><code>print_itemset(0, set([
</code><code>    (0,0),
</code><code>    (1,0),
</code><code>    (2,0),
</code><code>]))</code></pre>
<p>Implementation of the prediction step:</p>
<pre><code>def after_dot((rule, index)):
</code><code>    lhs, rhs = grammar[rule]
</code><code>    if index &lt; len(rhs):
</code><code>        return rhs[index]
</code><code>
</code><code>def predict(items):
</code><code>    prediction = set(items)
</code><code>    p = len(prediction)
</code><code>    while len(items) &gt; 0:
</code><code>        sym = after_dot(items.pop())
</code><code>        for index, (lhs,rhs) in enumerate(grammar):
</code><code>            if sym == lhs and sym is not None:
</code><code>                prediction.add((index, 0))
</code><code>                if p &lt; len(prediction):
</code><code>                    p = len(prediction)
</code><code>                    items.append((index,0))
</code><code>    return prediction</code></pre>
<p>To be honest I didn't get that right away.
The "and sym is not None" was added in the post.
And now we test it:</p>
<pre><code>print_itemset(0, predict([(0,0)]))</code></pre>
<p>You get the whole thing in a bit odd order,
but it's the initial itemset from the earlier.</p>
<pre><code>0: program → ∘ program declaration
</code><code>   program → ∘
</code><code>   ⊤ → ∘ program</code></pre>
<p>Now we can partition it into shifting sets:</p>
<pre><code>def partition(items):
</code><code>    groups = {}
</code><code>    for item in items:
</code><code>        sym = after_dot(item)
</code><code>        if sym is not None:
</code><code>            item = (item[0], item[1]+1)
</code><code>        try:
</code><code>            groups[sym].append(item)
</code><code>        except KeyError as _:
</code><code>            groups[sym] = [item]
</code><code>    return [(sym, frozenset(items)) for sym,items in groups.items()]</code></pre>
<p>And again try things out:</p>
<pre><code>for sym, items in partition(predict([(0,0)])):
</code><code>    print_itemset(sym, items)</code></pre>
<p>And we have some rudimentary shifting sets here.</p>
<pre><code>program: ⊤ → program ∘
</code><code>         program → program ∘ declaration
</code><code>None: program → ∘</code></pre>
<p>Now we can compute all itemsets:</p>
<pre><code>itemsets = [ frozenset([(0,0)]) ]
</code><code>itemsets_index = dict((s,i) for i,s in enumerate(itemsets))
</code><code>vectors = []
</code><code>full_itemsets = []
</code><code>shifts = []
</code><code>reductions = []
</code><code>for k, itemset in enumerate(itemsets):
</code><code>    vectors.append(tuple(itemset))
</code><code>    pset = predict(list(itemset))
</code><code>    full_itemsets.append(pset)
</code><code>    print_itemset(k, itemset)
</code><code>    k_shifts = {}
</code><code>    k_reductions = set()
</code><code>    for sym, items in partition(pset):
</code><code>        if sym is None:
</code><code>            k_reductions.update(items)
</code><code>        else:
</code><code>            try:
</code><code>                j = itemsets_index[items]
</code><code>            except KeyError as _:
</code><code>                j = len(itemsets)
</code><code>                itemsets_index[items] = j
</code><code>                itemsets.append(items)
</code><code>            k_shifts[sym] = j
</code><code>    shifts.append(k_shifts)
</code><code>    reductions.append(k_reductions)
</code><code>print shifts
</code><code>print reductions</code></pre>
<p>The printout is the same as what we did before by hand:</p>
<pre><code>0: program → ∘ program declaration
</code><code>   program → ∘
</code><code>   ⊤ → ∘ program
</code><code>1: ⊤ → program ∘
</code><code>   declaration → ∘ varDecl
</code><code>   declaration → ∘ statement
</code><code>   program → program ∘ declaration
</code><code>   declaration → ∘ constDecl
</code><code>2: declaration → constDecl ∘
</code><code>3: declaration → varDecl ∘
</code><code>4: declaration → statement ∘
</code><code>5: program → program declaration ∘
</code><code>[{'program': 1},
</code><code> {'varDecl': 3, 'constDecl': 2, 'statement': 4, 'declaration': 5},
</code><code> {}, {}, {}, {}]
</code><code>[set([(1, 0)]),
</code><code> set([(0, 1)]),
</code><code> set([(4, 1)]),
</code><code> set([(3, 1)]),
</code><code> set([(5, 1)]),
</code><code> set([(2, 2)])]</code></pre>
<p>We see the shifts and reductions correspond with what we wrote by hand.
Now we have the itemsets resolved out.</p>
<h3>Computation of EMPTY -sets</h3>
<p>This is something I didn't cover,
but it's needed for computing the FIRST and FOLLOW sets.</p>
<pre><code>def empty_symbols():
</code><code>    symbols = set()
</code><code>    for lhs,rhs in grammar:
</code><code>        if len(rhs) == 0:
</code><code>            symbols.add(lhs)
</code><code>    m = 0
</code><code>    n = len(symbols)
</code><code>    while m &lt; n:
</code><code>        for lhs, rhs in grammar:
</code><code>            if all(x in symbols for x in rhs):
</code><code>                symbols.add(lhs)
</code><code>        m = n
</code><code>        n = len(symbols)
</code><code>    return symbols
</code><code>empty = empty_symbols()</code></pre>
<p>Empty symbols aren't common things in grammars,
but they add bit of extra work.</p>
<h3>Computation of FIRST -sets</h3>
<p>Construction of 'FIRST' sets were not the simplest thing either.
It took me few tries to get it right.</p>
<pre><code>def first_lexemes():
</code><code>    symbols = dict()
</code><code>    routes = set()
</code><code>    for sym in lexemes:
</code><code>        symbols[sym] = set([sym])
</code><code>    for lhs, rhs in grammar:
</code><code>        if lhs not in symbols:
</code><code>            symbols[lhs] = set([])
</code><code>    for lhs, rhs in grammar:
</code><code>        for rhsN in rhs:
</code><code>            routes.add((lhs,rhsN))
</code><code>            if rhsN not in empty:
</code><code>                break
</code><code>    rep = True
</code><code>    while rep:
</code><code>        rep = False
</code><code>        for lhs, rhs0 in routes:
</code><code>            n = len(symbols[lhs])
</code><code>            symbols[lhs].update(symbols[rhs0])
</code><code>            rep |= n &lt; len(symbols[lhs])
</code><code>    return symbols
</code><code>
</code><code>first = first_lexemes()
</code><code>print first</code></pre>
<p>The result is what you'd expect by now.
Bit of a jumble but it has the gist:</p>
<pre><code>{'statement': set(['statement']),
</code><code> 'varDecl': set(['varDecl']),
</code><code> 'program': set(['statement', 'varDecl', 'constDecl']),
</code><code> None: set(['statement', 'constDecl', 'varDecl']),
</code><code> 'declaration': set(['varDecl', 'constDecl', 'statement']),
</code><code> 'constDecl': set(['constDecl'])}</code></pre>
<p>Next the follow set for each itemset.</p>
<h3>Computation of FOLLOW -sets</h3>
<p>FOLLOW set records the information of what can follow which item.
This allows to find out how the predicted items should behave.</p>
<pre><code>def follow_lexemes(seedset, full_itemset):
</code><code>    symbols = {}
</code><code>    seeds = {}
</code><code>    routes = set()
</code><code>    for item in full_itemset:
</code><code>        sym0 = after_dot(item)
</code><code>        if sym0 not in symbols:
</code><code>            symbols[sym0] = set()
</code><code>            seeds[sym0] = set()
</code><code>    for rule,index in full_itemset:
</code><code>        lhs,rhs = grammar[rule]
</code><code>        if index &lt; len(rhs):
</code><code>            rhs0 = rhs[index]
</code><code>            k = index+1
</code><code>            for k in range(index+1, len(rhs)):
</code><code>                symbols[rhs0].update(first[rhs[k]])
</code><code>                if rhs[k] not in empty:
</code><code>                    break
</code><code>            if k == len(rhs):
</code><code>                if (rule,index) in seedset:
</code><code>                    seeds[rhs0].add((rule,index))
</code><code>                else:
</code><code>                    routes.add((lhs, rhs0))
</code><code>    rep = True
</code><code>    while rep:
</code><code>        rep = False
</code><code>        for lhs, sym in routes:
</code><code>            n = len(symbols[lhs])
</code><code>            symbols[lhs].update(symbols[rhs0])
</code><code>            rep |= n &lt; len(symbols[lhs])
</code><code>            n = len(seeds[lhs])
</code><code>            seeds[lhs].update(seeds[rhs0])
</code><code>            rep |= n &lt; len(seeds[lhs])
</code><code>    return symbols, seeds</code></pre>
<p>And then we try it out:</p>
<pre><code>follow_syms = []
</code><code>follow_seeds = []
</code><code>
</code><code>for i in range(len(itemsets)):
</code><code>    syms,seeds = follow_lexemes(itemsets[i], full_itemsets[i])
</code><code>    follow_syms.append(syms)
</code><code>    follow_seeds.append(seeds)
</code><code>    print i
</code><code>    print syms
</code><code>    print seeds</code></pre>
<p>These sets are quite barren in the grammar that we test with.
If I did a mistake anywhere here, I guess it's not visible yet.</p>
<pre><code>0
</code><code>{'program': set(['constDecl', 'varDecl', 'statement']), None: set([])}
</code><code>{'program': set([(0, 0)]), None: set([])}
</code><code>1
</code><code>{'constDecl': set([]), 'varDecl': set([]), 'statement': set([]),
</code><code> None: set([]), 'declaration': set([])}
</code><code>{'constDecl': set([]), 'varDecl': set([]), 'statement': set([]),
</code><code> None: set([]), 'declaration': set([(2, 1)])}
</code><code>2
</code><code>{None: set([])}
</code><code>{None: set([])}
</code><code>3
</code><code>{None: set([])}
</code><code>{None: set([])}
</code><code>4
</code><code>{None: set([])}
</code><code>{None: set([])}
</code><code>5
</code><code>{None: set([])}
</code><code>{None: set([])}</code></pre>
<p>We've went through what this should mean,
so it should be possible to wean out any bugs by inspecting the results
once they're there.</p>
<h3>Build-up of the LR(1) decision tables</h3>
<p>If you were reading through the snippet,
you may be wondering what we are going to do with the <code>vectors</code> -structure,
or then you're really smart and figured it out.</p>
<p>We are going to use the lookahead sets as indices into a 'function'
that builds the full decision table.</p>
<pre><code>fin_index = {}
</code><code>fin_vectors = []
</code><code>fin_tabs = []
</code><code>conflicts = {}
</code><code>
</code><code>def build_decision_table(k, *args):
</code><code>    fin_index[(k,)+args] = tab_index = len(fin_vectors)
</code><code>    fin_vectors.append((k,)+args)
</code><code>    tab = {}
</code><code>    fin_tabs.append(tab)
</code><code>    assert len(vectors[k]) == len(args)
</code><code>    seed_lookahead = dict(zip(vectors[k],args))
</code><code>    syms = follow_syms[k]
</code><code>    seeds = follow_seeds[k]
</code><code>    for sym, j in shifts[k].items():
</code><code>        args = (j,) + tuple(
</code><code>            frozenset(followup(k, seed_lookahead, (s_item[0], s_item[1]-1)))
</code><code>            for s_item in vectors[j])
</code><code>        if args in fin_index:
</code><code>            tab[sym] = (0, fin_index[args])
</code><code>        else:
</code><code>            tab[sym] = (0, build_decision_table(*args))
</code><code>    had_conflicts = []
</code><code>    for reditem in reductions[k]:
</code><code>        for sym in followup(k, seed_lookahead, reditem):
</code><code>            action = ('reduce',
</code><code>                grammar[reditem[0]][0],
</code><code>                len(grammar[reditem[0]][1]),
</code><code>                reditem[0])
</code><code>            if sym in tab:
</code><code>                if (k,sym) in conflicts:
</code><code>                    conflicts[(k,sym)].append(action)
</code><code>                else:
</code><code>                    conflicts[(k,sym)] = [tab[sym], action]
</code><code>                    had_conflicts.append((k,sym))
</code><code>            else:
</code><code>                tab[sym] = action
</code><code>    if len(had_conflicts) &gt; 0:
</code><code>        print("Conflicts:".format(had_conflicts))
</code><code>        for cnf in had_conflicts:
</code><code>            print(" {}: {}".format(cnf, conflicts[cnf]))
</code><code>    return tab_index
</code><code>
</code><code>build_decision_table(0, frozenset([None]))
</code><code>if len(conflicts) &gt; 0:
</code><code>    print fin_tabs
</code><code>    print conflicts
</code><code>else:
</code><code>    print fin_tabs</code></pre>
<p>Just like I adviced on building actual parser,
this thing collects conflicts and presents them as they appear.
Time to see how our grammar baked through:</p>
<pre><code>[{'constDecl': ('reduce', 'program', 0, 1),
</code><code>  'program':   (0, 1),
</code><code>  'varDecl':   ('reduce', 'program', 0, 1),
</code><code>  'statement': ('reduce', 'program', 0, 1),
</code><code>  None:        ('reduce', 'program', 0, 1)},
</code><code> {'constDecl':   (0, 3),
</code><code>  'varDecl':     (0, 2),
</code><code>  None:          ('reduce', None, 1, 0),
</code><code>  'statement':   (0, 4),
</code><code>  'declaration': (0, 5)},
</code><code>{'varDecl':   ('reduce', 'declaration', 1, 3),
</code><code> 'constDecl': ('reduce', 'declaration', 1, 3),
</code><code> None:        ('reduce', 'declaration', 1, 3),
</code><code> 'statement': ('reduce', 'declaration', 1, 3)},
</code><code>{'varDecl':   ('reduce', 'declaration', 1, 4),
</code><code> 'constDecl': ('reduce', 'declaration', 1, 4),
</code><code> None:        ('reduce', 'declaration', 1, 4),
</code><code> 'statement': ('reduce', 'declaration', 1, 4)},
</code><code>{'varDecl':   ('reduce', 'declaration', 1, 5),
</code><code> 'constDecl': ('reduce', 'declaration', 1, 5),
</code><code> None:        ('reduce', 'declaration', 1, 5),
</code><code> 'statement': ('reduce', 'declaration', 1, 5)},
</code><code>{'varDecl':   ('reduce', 'program', 2, 2),
</code><code> 'constDecl': ('reduce', 'program', 2, 2),
</code><code> None:        ('reduce', 'program', 2, 2),
</code><code> 'statement': ('reduce', 'program', 2, 2)}]</code></pre>
<p>It looks a lot like it succeeded.</p>
<h2>That WFB/VALIGN -thing?</h2>
<p>I didn't get to do it yet,
but I know you may be very interested about
how to generate decision tables for layout-constrained grammars.</p>
<p>Well first of all you need to have 'wfb<em>constraints'
and 'valign</em>constraints' -sets.
These will provide indices to rules and items with these constraints.</p>
<pre><code>wfb_constraints = [(1,0), (1,1)]
</code><code>valign_constraints = [(1,1)]</code></pre>
<p>Next you have to check during prediction,
that every prediction were made with same WFB/VALIGN guards.
Mark the WFB/VALIGN conditions into shifting symbols.
Bit like this:</p>
<pre><code>def predict(items):
</code><code>    prediction = set(items)
</code><code>    wfb = set()
</code><code>    valign = set()
</code><code>    cconflicts = []
</code><code>    p = len(prediction)
</code><code>    while len(items) &gt; 0:
</code><code>        this = items.pop()
</code><code>        has_wfb = this in wfb_constraints or this in wfb
</code><code>        has_valign = this in valign_constraints or this in valign
</code><code>        sym = after_dot(this)
</code><code>        for index, (lhs,rhs) in enumerate(grammar):
</code><code>            if sym == lhs and sym is not None:
</code><code>                prediction.add((index, 0))
</code><code>                if p &lt; len(prediction):
</code><code>                    p = len(prediction)
</code><code>                    items.append((index,0))
</code><code>                    if has_wfb:
</code><code>                        wfb.add((index,0))
</code><code>                    if has_valign:
</code><code>                        valign.add((index,0))
</code><code>                else:
</code><code>                    if ((index,0) in wfb) ^ has_wfb:
</code><code>                        cconflicts.append(('wfb', (index,0)))
</code><code>                    if ((index,0) in valign) ^ has_valign:
</code><code>                        cconflicts.append(('valign', (index,0)))
</code><code>    return prediction, wfb, valign, cconflicts</code></pre>
<p>In the follow-set buildup you detect WFB+VALIGN -guarded clauses.</p>
<pre><code>for rule,index in full_itemset:
</code><code>    lhs,rhs = grammar[rule]
</code><code>    has_wfb = (rule,index) in wfb_constraints
</code><code>    if index &lt; len(rhs):
</code><code>        rhs0 = rhs[index]
</code><code>        k = index+1
</code><code>        for k in range(index+1, len(rhs)):
</code><code>            if (rule,k) in valign_constraints:
</code><code>                symbols[rhs0].add('wfb')
</code><code>            else:
</code><code>                symbols[rhs0].update(first[rhs[k]])
</code><code>            if rhs[k] not in empty:
</code><code>                break
</code><code>        if k == len(rhs):
</code><code>            if (rule,index) in seedset:
</code><code>                seeds[rhs0].add((rule,index))
</code><code>            else:
</code><code>                routes.add((lhs, rhs0))</code></pre>
<p>Finally when building the decision tables, mark the states with the guards.</p>
<pre><code>def partition(items, wfb, valign, cconflicts):
</code><code>    groups = {}
</code><code>    modes = {}
</code><code>    for item in items:
</code><code>        sym = after_dot(item)
</code><code>        mode = (int(item in wfb) &lt;&lt; 1) | int(item in valign)
</code><code>        if sym is not None:
</code><code>            item = (item[0], item[1]+1)
</code><code>        try:
</code><code>            groups[sym].append(item)
</code><code>            if modes[sym] != mode:
</code><code>                cconflicts.append(('shift+valign+wfb', sym))
</code><code>        except KeyError as _:
</code><code>            groups[sym] = [item]
</code><code>            modes[sym] = mode
</code><code>    return [(sym, frozenset(items), modes[sym])
</code><code>        for sym, items in groups.items()]</code></pre>
<p>I've supplied the whole code for the generator into the
<a href="https://boxbase.org/entries/2019/oct/14/lr1-parsing-tables/parsergen.py">parsergen.py</a> -file and I attached it into this blog post.</p>
<p>Anyway the real point of this point was not to share code snippets,
but to illustrate how simple and easy it is to build a LR parser,
even by hand.
Although the work should be carefully inspected afterwards.
Make some mistake into the table and it won't parse the right language.</p>
<h2>Now's your chance</h2>
<p>If you contact me this October, either by email or sending a message to,
the reddit post in <code>r/programminglanguages</code> that discusses this blog post.
I will help you build a parser for your language, as featured above.
And if you like to, I will feature your language in this blog,
among other people's languages.</p>
<p>It doesn't need to be a programming language or otherwise a serious project.
The finished language can be written any common programming language,
as long as you know that language well yourself.
Though, I will stick to using Python for the parsing generator part.</p>
<p>Every submitted language will be described with the following kind of grammar:</p>
<pre><code>grammar: 
</code><code>grammar: grammar VALIGN WFB declaration
</code><code>declaration:
</code><code>    identifier ":" rhs_block
</code><code>    "lexemes" identifiers
</code><code>rhs_block:
</code><code>rhs_block: rhs_block VALIGN WFB rhs
</code><code>rhs: 
</code><code>rhs: rhs symbol
</code><code>symbol: "VALIGN" symbol
</code><code>        "WFB" symbol
</code><code>        identifier
</code><code>        string
</code><code>identifiers: identifier
</code><code>             identifiers "," identifier
</code><code>lexemes identifier, string</code></pre>
<p>You don't need to have this kind of a grammar with you when you contact,
but I will make the parser generator use this grammar later this week.</p>
<h2>Usecases</h2>
<p>Obviously if you wanted to build a programming language you need a parser.
But it could be that you just stumbled on this and
wonder if it's useful for you.</p>
<p>Here's example of some things you can do with a working LR parser:</p>
<ol>
<li>Some communication protocols are described with context-free grammars.
In those cases it's possible you can use LR parser to interpret the protocol.</li>
<li>C programming language has a LR-specific parser hack where it
inserts new types through 'typedef' statements.
It takes effect immediately after semicolon of the typedef statement
and I think that followed scopes as well.
So it's not very fun to parse with other means than implementing the
LR parser and the syntax hack.</li>
<li>LR parsers can be used in inverse, just like many other parsers.
Instead of giving in symbols
you may gather the symbols the parser expects to see
and then present them to the user.
It could be useful for somebody who wants to write a game
or a graphical editor of some kind.
Or otherwise implement some kind of a different user interface.</li>
</ol>
</article>
<nav id="article-nav">
<a href="https://boxbase.org/">index</a>
<a href="https://boxbase.org/entries/2019/oct/4/flaws-in-structured-programming">prev</a>
<a href="https://boxbase.org/entries/2019/oct/21/layout-sensitive-lr">next</a>
</nav>
<nav id="page-nav">
<a href="feed://boxbase.org/feed.rss">rss</a>
<a href="https://boxbase.org/catalog/">catalog</a>
<a href="https://github.com/cheery/">github</a>
<a href="https://boxbase.org/trash/mailchimp.html">subscription-list</a>
</nav>
<footer>
<p>Blog author: <a href="https://boxbase.org/entries/2020/jul/30/about-the-author/">Henri Tuhola</a>, a Finnish self-taught programmer and an electronics enthusiast.</p>
<p>I enjoy programming, program design, programming language design, algorithms, steam OS,
        game programming, Vulkan, virtual reality, WebGL, DIY electronics, Internet,
        gardening, fitness. This blog represents a cross-section of all of my interests.
        (It's mostly programming language studies and occassional programming guides in middle)</p>
<p>I am also the author of <a href="https://leverlanguage.com/">Lever programming language</a>.
           This is a programming language I made,
           but since then figured out I could make a better one that's not dynamically typed.</p>
<p>I usually update the blog every week or two.
           You may feedback me with an <a href="mailto:henri.tuhola@gmail.com">email</a>
           or <a href="https://twitter.com/HenriTuhola">twitter</a>.
           I appreciate corrections and improvements to texts.</p>
<div id="license">
<a href="http://creativecommons.org/licenses/by/4.0/" rel="license"><img alt="Creative Commons License" src="./How to write your own LR(1) parsing tables (and generate them)_files/88x31.png" style="border-width:0"></a><br>This work is licensed under a <a href="http://creativecommons.org/licenses/by/4.0/" rel="license">Creative Commons Attribution 4.0 International License</a>.
        </div>
</footer>


</body></html>